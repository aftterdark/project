import tensorflow as tf

# Загружаем данные MNIST
mnist = tf.keras.datasets.mnist
(tx, ty), (vx, vy) = mnist.load_data()

# Предобработка данных
tx = tx[:,:,:,None].astype('float32')
vx = vx[:,:,:,None].astype('float32')
ty = ty.astype(int)
vy = vy.astype(int)

# Создаём модель
def normConvBlock(filters, return_model=True, name=None):
  lays = [
    tf.keras.layers.Conv2D(filters, 3, padding='valid', name=name+'_conv'),
    tf.keras.layers.BatchNormalization(name=name+'_bn'),
    tf.keras.layers.Activation('relu', name=name+'_act'),
    tf.keras.layers.MaxPooling2D(2, strides=2, name=name+'_mpool'),
    tf.keras.layers.Dropout(0.1, name=name+'_drop'),
  ]

  if return_model:
    return tf.keras.models.Sequential(lays, name=name)
  else:
    return lays

# Модель
model = tf.keras.models.Sequential()
model.add(normConvBlock(64, name='b1'))
model.add(normConvBlock(128, name='b2'))
model.add(tf.keras.layers.Flatten(name='flat'))
model.add(tf.keras.layers.Dense(10, activation='softmax', name='logit'))

# Компиляция модели
model.compile('adam', 'sparse_categorical_crossentropy', metrics=['acc'])

# Обучение модели
es_call = tf.keras.callbacks.EarlyStopping(
    monitor='val_loss', min_delta=0, patience=2, verbose=0,
    mode='auto', baseline=None, restore_best_weights=True
)

history = model.fit(tx, ty, validation_data=(vx, vy), epochs=20, batch_size=1024, callbacks=[es_call])

# Сохраняем модель в формат TensorFlow.js
import tensorflowjs
tensorflowjs.converters.save_keras_model(model, './mnist_tf_keras_js_model/')

# После этого можно скачать файлы модели:
# files.download("mnist_tf_keras_js_model/model.json")
# files.download("mnist_tf_keras_js_model/group1-shard1of1.bin")
